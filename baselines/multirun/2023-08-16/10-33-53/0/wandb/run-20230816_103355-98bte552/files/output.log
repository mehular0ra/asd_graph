[2023-08-16 10:33:58][__main__.py][L41][INFO]dataset:
  name: fc_bnt
  batch_size: 16
  train_set: 0.9
  test_set: 0.1
  fc_path: /mnt/ssd1/mehul_data/research/fc_bnt_data.npy
  node_sz: 200
  node_feature_sz: 200
  num_classes: 2
  perc_edges: 100
  node: one_hot
model:
  name: GraphSAGE
  num_layers: 2
  hidden_size: 64
  dropout: 0.5
  readout: mean
  edge_percentage: 0.1
optimizer:
- name: Adam
  lr: 0.0001
  match_rule: None
  except_rule: None
  no_weight_decay: false
  weight_decay: 0.0001
  lr_scheduler:
    mode: poly
    base_lr: 0.0001
    target_lr: 1.0e-05
    decay_factor: 0.1
    milestones:
    - 0.3
    - 0.6
    - 0.9
    poly_power: 2.0
    lr_decay: 0.98
    warm_up_from: 0.0
    warm_up_steps: 0
training:
  name: Train
  epochs: 100
  l2: 0.0
log_path: result
repeat_time: 5
device: cuda:0
is_wandb: true
project: asd-graph
[2023-08-16 10:33:58][__init__.py][L15][INFO]cfg.dataset.name: fc_bnt
GraphSAGE(
  (convs): ModuleList(
    (0): SAGEConv(200, 64, aggr=mean)
    (1): SAGEConv(64, 64, aggr=mean)
  )
  (readout_lin): Linear(in_features=12800, out_features=64, bias=True)
  (lin): Linear(in_features=64, out_features=1, bias=True)
)
[2023-08-16 10:34:01][optimizer.py][L66][INFO]Parameters [normal] length [10]
[2023-08-16 10:34:01][__init__.py][L25][INFO]Training: Train
[2023-08-16 10:34:02][Train.py][L35][INFO]#model params: 853249
Starting training...
[2023-08-16 10:34:02,009][HYDRA] 	#1 : dataset=fc_bnt model=gat
/home/mehul/.conda/envs/pyg/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/mehul/.conda/envs/pyg/lib/python3.11/site-packages/hydra/_internal/core_plugins/basic_launcher.py:74: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(