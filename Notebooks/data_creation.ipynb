{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing ZIP files\n",
    "directory_path = '/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200'\n",
    "csv_path = './ABIDEII_Composite_Phenotypic.csv'  \n",
    "\n",
    "# Read CSV file\n",
    "csv_data = pd.read_csv(csv_path,  encoding='ISO-8859-1')\n",
    "csv_data['SEX'].replace({2: 0}, inplace=True)\n",
    "csv_data['DX_GROUP'].replace({2: 0}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-NYU_2\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII_GU_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII_IP_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII_EMC_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-NYU_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-UCLA_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-KKI_1_29424_29485\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-KKI_1_29273_29322\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-KKI_1_29373_29423\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-U_MIA_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII_IU_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-SDSU_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-USM_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-KKI_1_29323_29372\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-UCD_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-KUL_3\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII_BNI_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII_ETH_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-OHSU_1\n",
      "/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/ABIDEII-TCD_1\n"
     ]
    }
   ],
   "source": [
    "# Iterate through ZIP files\n",
    "base_path = '/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/'\n",
    "\n",
    "# List the ZIP files in the directory\n",
    "zip_files = [f for f in os.listdir(base_path) if f.endswith('.zip')]\n",
    "\n",
    "for zip_file_name in zip_files:\n",
    "    zip_path = os.path.join(base_path, zip_file_name)\n",
    "    # Construct the extracted folder path without .zip\n",
    "    extracted_folder_path = os.path.join(base_path, zip_file_name[:-4])\n",
    "    print(extracted_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### combining KK1_1 data\n",
    "\n",
    "# # Create a target directory for combined data\n",
    "# combined_path = os.path.join(base_path, 'ABIDEII-KKI_1')\n",
    "# os.makedirs(combined_path, exist_ok=True)\n",
    "\n",
    "# # List the ZIP files in the directory\n",
    "# zip_files = [f for f in os.listdir(base_path) if f.endswith('.zip') and 'KKI_1' in f]\n",
    "\n",
    "# for zip_file_name in zip_files:\n",
    "#     zip_path = os.path.join(base_path, zip_file_name)\n",
    "\n",
    "#     # Temporary extraction path\n",
    "#     extracted_folder_path = os.path.join(base_path, zip_file_name[:-4])\n",
    "\n",
    "#     # Unzip the file\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "#     # Move the extracted contents to the combined directory\n",
    "#     for subject_file in os.listdir(extracted_folder_path):\n",
    "#         shutil.move(os.path.join(extracted_folder_path,\n",
    "#                     subject_file), combined_path)\n",
    "\n",
    "#     # Remove temporary extraction path\n",
    "#     shutil.rmtree(extracted_folder_path)\n",
    "\n",
    "# print(f\"Combined all KKI_1 data into: {combined_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site name:  NYU_2\n",
      "Site name:  GU_1\n",
      "Site name:  IP_1\n",
      "Site name:  EMC_1\n",
      "Site name:  NYU_1\n",
      "Site name:  UCLA_1\n",
      "Site name:  MIA_1\n",
      "Site name:  IU_1\n",
      "Site name:  SDSU_1\n",
      "Site name:  USM_1\n",
      "Site name:  UCD_1\n",
      "Site name:  KUL_3\n",
      "Site name:  KKI_1\n",
      "Site name:  BNI_1\n",
      "Site name:  ETH_1\n",
      "Site name:  OHSU_1\n",
      "Site name:  TCD_1\n"
     ]
    }
   ],
   "source": [
    "# Define final data structure\n",
    "fc_data = {\n",
    "    'corr': [],\n",
    "    'label': [],\n",
    "    'site': [],\n",
    "    'age': [],\n",
    "    'sex': []\n",
    "}\n",
    "\n",
    "# Iterate through ZIP files\n",
    "base_path = '/mnt/ssd1/mehul_data/ABIDE2/abide2_fc_200/'\n",
    "\n",
    "# List the ZIP files in the directory\n",
    "zip_files = [f for f in os.listdir(base_path) if f.endswith('.zip')]\n",
    "\n",
    "for zip_file_name in zip_files:\n",
    "    zip_path = os.path.join(base_path, zip_file_name)\n",
    "    # Construct the extracted folder path without .zip\n",
    "    extracted_folder_path = os.path.join(base_path, zip_file_name[:-4])\n",
    "\n",
    "    site_name_parts = re.split('[_-]', extracted_folder_path)\n",
    "    site_name = '_'.join(site_name_parts[-2:])\n",
    "    print(\"Site name: \", site_name)\n",
    "\n",
    "    # Unzip the file if not already unzipped\n",
    "    if not os.path.exists(extracted_folder_path):\n",
    "        os.mkdir(extracted_folder_path)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "    # Iterate through subject data\n",
    "    extracted_folder_path = zip_path.replace('.zip', '')\n",
    "    for subject_folder in os.listdir(extracted_folder_path):\n",
    "        subject_id_str = subject_folder.split('_')[0]\n",
    "        subject_id = int(subject_id_str.split('-')[1])\n",
    "\n",
    "        # Get corresponding CSV row\n",
    "        row = csv_data[csv_data['SUB_ID'] == subject_id]\n",
    "        if row.empty:\n",
    "            continue\n",
    "\n",
    "        # Assume 'corr' file is located within the subject folder\n",
    "        corr_file_name = f'{subject_id_str}_connectomes.csv'\n",
    "        corr_file_path = os.path.join(\n",
    "            extracted_folder_path, subject_folder, corr_file_name)\n",
    "\n",
    "        # Load correlation data from CSV\n",
    "        # Adjust loading method if necessary\n",
    "        corr_data = pd.read_csv(corr_file_path, header=None).values\n",
    "\n",
    "        fc_data['corr'].append(corr_data)\n",
    "        fc_data['label'].append(row['DX_GROUP'].values[0])\n",
    "        fc_data['site'].append(site_name)\n",
    "        fc_data['age'].append(row['AGE_AT_SCAN '].values[0])\n",
    "        fc_data['sex'].append(row['SEX'].values[0])\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "for key, value in fc_data.items():\n",
    "    fc_data[key] = np.array(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['corr', 'label', 'site', 'age', 'sex'])\n",
      "(812, 200, 200)\n",
      "(812,)\n",
      "(812,)\n",
      "(812,)\n",
      "(812,)\n"
     ]
    }
   ],
   "source": [
    "print(fc_data.keys())\n",
    "print(fc_data['corr'].shape)\n",
    "print(fc_data['label'].shape)\n",
    "print(fc_data['site'].shape)\n",
    "print(fc_data['age'].shape)\n",
    "print(fc_data['sex'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "['BNI_1' 'EMC_1' 'ETH_1' 'GU_1' 'IP_1' 'IU_1' 'KKI_1' 'KUL_3' 'MIA_1'\n",
      " 'NYU_1' 'NYU_2' 'OHSU_1' 'SDSU_1' 'TCD_1' 'UCD_1' 'UCLA_1' 'USM_1']\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(fc_data['label']))\n",
    "print(np.unique(fc_data['site']))\n",
    "# print(np.unique(fc_data['age']))\n",
    "print(np.unique(fc_data['sex']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(812, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "print(fc_data['corr'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/mnt/ssd1/mehul_data/research/fc_abide2_200.npy\"\n",
    "np.save(save_path, fc_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['corr', 'label', 'site', 'age', 'sex'])\n",
      "(812, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "load_path = \"/mnt/ssd1/mehul_data/research/fc_abide2_200.npy\"\n",
    "loaded_data = np.load(load_path, allow_pickle=True).item()\n",
    "\n",
    "# Check the loaded data (e.g., print shape, some elements, etc.)\n",
    "print(loaded_data.keys())\n",
    "print(loaded_data['corr'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypergraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
