defaults: 
  - dataset: fc_large
  - model: dwhgn   # dwhgn,hypergraphgcn dwattnhgn,attnhgn
  - optimizer: adam
  - training: train


dataset:
  node: fc
  train_set: 0.9
  test_set: 0.1
  batch_size: 16


model: 
  K_neigs: 40 #5, 10, 25, 40, 60, 100
  num_layers: 1 #2, 3, 5
  hidden_size: 64  # 8, 16, 32, 64, 128
  dropout: 0.5     # 0.25
  heads: 1
  readout: linear #linear, set_transformer, janossy, max, mean
  attention_mode: edge
  num_perm: 25

  node_attn_interpret: True
  node_attn_learn: True
  node_attn_save: False

  tsne: False
  tsne_train: False

  gradcam: False
  ####
  model_save: True
  
  save_interpret: False
  save_epochs: [0, 19, 50, 99]

log_path: result

repeat_time: 5
kfold: True
kfold_val: -1

# total_steps: 100 # remove this later

device: cuda

# wandb:
is_wandb: False
# doing_sweep: True
project: icassp
entity: mehular0ra
# sweep_id: asd-graph/asd-graph/r49h4avh



hydra:
  job_logging:
    root:
      handlers: [console, file]
      propagate: true
    formatters:
      precise:
        format: '[%(asctime)s][%(filename)s][L%(lineno)d][%(levelname)s]%(message)s'
        datefmt: '%Y-%m-%d %H:%M:%S'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: precise
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: precise
        filename: ./output.log

